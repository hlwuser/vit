{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":1808590,"datasetId":989445,"databundleVersionId":1846062,"isSourceIdPinned":false}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:36:57.854745Z","iopub.execute_input":"2026-01-17T08:36:57.855023Z","iopub.status.idle":"2026-01-17T08:36:58.955945Z","shell.execute_reply.started":"2026-01-17T08:36:57.854992Z","shell.execute_reply":"2026-01-17T08:36:58.955122Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport tiktoken\nfrom tqdm import tqdm\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:05:04.740955Z","iopub.execute_input":"2026-01-17T11:05:04.741284Z","iopub.status.idle":"2026-01-17T11:05:04.745892Z","shell.execute_reply.started":"2026-01-17T11:05:04.741254Z","shell.execute_reply":"2026-01-17T11:05:04.745108Z"}},"outputs":[],"execution_count":150},{"cell_type":"code","source":"CONFIG = {\n    \"vocab_size\": 50257,    # Vocabulary size\n    \"context_length\": 80, # Context length\n    \"emb_dim\": 768,         # Embedding dimension\n    \"n_heads\": 6,          # Number of attention heads\n    \"n_layers\": 6,         # Number of layers\n    \"drop_rate\": 0.1,       # Dropout rate\n    \"qkv_bias\": False       # Query-Key-Value bias\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:33:13.648629Z","iopub.execute_input":"2026-01-17T10:33:13.649231Z","iopub.status.idle":"2026-01-17T10:33:13.652842Z","shell.execute_reply.started":"2026-01-17T10:33:13.649189Z","shell.execute_reply":"2026-01-17T10:33:13.652196Z"}},"outputs":[],"execution_count":125},{"cell_type":"code","source":"EOT_TOKEN_ID = 50256 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:54:54.337085Z","iopub.execute_input":"2026-01-17T08:54:54.337393Z","iopub.status.idle":"2026-01-17T08:54:54.341423Z","shell.execute_reply.started":"2026-01-17T08:54:54.337367Z","shell.execute_reply":"2026-01-17T08:54:54.340821Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:42:28.396281Z","iopub.execute_input":"2026-01-17T08:42:28.396584Z","iopub.status.idle":"2026-01-17T08:42:31.937835Z","shell.execute_reply.started":"2026-01-17T08:42:28.396558Z","shell.execute_reply":"2026-01-17T08:42:31.937223Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"\nclass SelfAttention(nn.Module):\n\n    def __init__(self, d_in, d_out, context_length, qkv_bias=False):\n        super().__init__()\n        self.d_out = d_out\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key   = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.dropout = nn.Dropout(0.01) # New\n        \n\n    def forward(self, x, attention_mask=None):\n        b, num_tokens, d_in = x.shape\n        keys    = self.W_key(x)\n        queries = self.W_query(x)\n        values  = self.W_value(x)\n    \n        # Compute raw attention scores\n        attn_scores = queries @ keys.transpose(1, 2)\n    \n        # Apply mask if provided\n        if attention_mask is not None:\n            # attention_mask shape: (B, seq_len)\n            # expand to (B, 1, seq_len) to broadcast over query positions\n            mask = attention_mask[:, None, :]\n            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n    \n        # Softmax + dropout\n        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n        attn_weights = self.dropout(attn_weights)\n    \n        # Weighted sum\n        context_vec = attn_weights @ values\n        return context_vec\n\n        \nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n            GELU(), ## Activation\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n        )\n\n    def forward(self, x):\n        return self.layers(x)\nclass MultiHeadAttentionWrapper(nn.Module):\n\n    def __init__(self, d_in, d_out, context_length, num_heads, qkv_bias=False):\n        super().__init__()\n        self.heads = nn.ModuleList(\n            [SelfAttention(d_in, d_out, context_length, qkv_bias) \n             for _ in range(num_heads)]\n        )\n\n    def forward(self, x,mask):\n        return torch.cat([head(x,mask) for head in self.heads], dim=-1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:04:29.208587Z","iopub.execute_input":"2026-01-17T11:04:29.209270Z","iopub.status.idle":"2026-01-17T11:04:29.218985Z","shell.execute_reply.started":"2026-01-17T11:04:29.209240Z","shell.execute_reply":"2026-01-17T11:04:29.218218Z"}},"outputs":[],"execution_count":145},{"cell_type":"code","source":"class GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n            (x + 0.044715 * torch.pow(x, 3))\n        ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:04:30.278558Z","iopub.execute_input":"2026-01-17T11:04:30.279460Z","iopub.status.idle":"2026-01-17T11:04:30.283887Z","shell.execute_reply.started":"2026-01-17T11:04:30.279428Z","shell.execute_reply":"2026-01-17T11:04:30.283231Z"}},"outputs":[],"execution_count":146},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttentionWrapper(\n            d_in=cfg[\"emb_dim\"],\n            d_out=cfg[\"emb_dim\"],\n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"], \n            qkv_bias=cfg[\"qkv_bias\"])\n        self.ff = FeedForward(cfg)\n        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x,mask):\n        # Shortcut connection for attention block\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x,mask)  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        # Shortcut connection for feed forward block\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        # 2*4*768\n        x = self.drop_shortcut(x)\n        x = x + shortcut  # Add the original input back\n\n        return x\n        # 2*4*768","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:06:07.328429Z","iopub.execute_input":"2026-01-17T11:06:07.328948Z","iopub.status.idle":"2026-01-17T11:06:07.335082Z","shell.execute_reply.started":"2026-01-17T11:06:07.328917Z","shell.execute_reply":"2026-01-17T11:06:07.334475Z"}},"outputs":[],"execution_count":152},{"cell_type":"code","source":"class GPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n        \n        self.trf_blocks = nn.Sequential(\n            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n        \n        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(\n            cfg[\"emb_dim\"], 2, bias=True\n        )\n\n    def forward(self, in_idx,mask):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n        x = self.drop_emb(x)\n        x = self.trf_blocks(x,mask)\n        x = self.final_norm(x)\n        logits = self.out_head(x)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:06:38.778406Z","iopub.execute_input":"2026-01-17T11:06:38.779038Z","iopub.status.idle":"2026-01-17T11:06:38.785173Z","shell.execute_reply.started":"2026-01-17T11:06:38.779009Z","shell.execute_reply":"2026-01-17T11:06:38.784403Z"}},"outputs":[],"execution_count":154},{"cell_type":"code","source":"import pandas\ndataset=pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/train.csv\",encoding=\"latin1\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:04.596503Z","iopub.execute_input":"2026-01-17T10:06:04.597090Z","iopub.status.idle":"2026-01-17T10:06:04.695586Z","shell.execute_reply.started":"2026-01-17T10:06:04.597065Z","shell.execute_reply":"2026-01-17T10:06:04.695031Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"dataset.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:06.451868Z","iopub.execute_input":"2026-01-17T10:06:06.452150Z","iopub.status.idle":"2026-01-17T10:06:06.462887Z","shell.execute_reply.started":"2026-01-17T10:06:06.452126Z","shell.execute_reply":"2026-01-17T10:06:06.462257Z"}},"outputs":[{"execution_count":106,"output_type":"execute_result","data":{"text/plain":"       textID                                               text  \\\n0  cb774db0d1                I`d have responded, if I were going   \n1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n2  088c60f138                          my boss is bullying me...   \n3  9642c003ef                     what interview! leave me alone   \n4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n\n                         selected_text sentiment Time of Tweet Age of User  \\\n0  I`d have responded, if I were going   neutral       morning        0-20   \n1                             Sooo SAD  negative          noon       21-30   \n2                          bullying me  negative         night       31-45   \n3                       leave me alone  negative       morning       46-60   \n4                        Sons of ****,  negative          noon       60-70   \n\n       Country  Population -2020  Land Area (Km²)  Density (P/Km²)  \n0  Afghanistan          38928346         652860.0               60  \n1      Albania           2877797          27400.0              105  \n2      Algeria          43851044        2381740.0               18  \n3      Andorra             77265            470.0              164  \n4       Angola          32866272        1246700.0               26  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>textID</th>\n      <th>text</th>\n      <th>selected_text</th>\n      <th>sentiment</th>\n      <th>Time of Tweet</th>\n      <th>Age of User</th>\n      <th>Country</th>\n      <th>Population -2020</th>\n      <th>Land Area (Km²)</th>\n      <th>Density (P/Km²)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cb774db0d1</td>\n      <td>I`d have responded, if I were going</td>\n      <td>I`d have responded, if I were going</td>\n      <td>neutral</td>\n      <td>morning</td>\n      <td>0-20</td>\n      <td>Afghanistan</td>\n      <td>38928346</td>\n      <td>652860.0</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>549e992a42</td>\n      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n      <td>Sooo SAD</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>21-30</td>\n      <td>Albania</td>\n      <td>2877797</td>\n      <td>27400.0</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>088c60f138</td>\n      <td>my boss is bullying me...</td>\n      <td>bullying me</td>\n      <td>negative</td>\n      <td>night</td>\n      <td>31-45</td>\n      <td>Algeria</td>\n      <td>43851044</td>\n      <td>2381740.0</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9642c003ef</td>\n      <td>what interview! leave me alone</td>\n      <td>leave me alone</td>\n      <td>negative</td>\n      <td>morning</td>\n      <td>46-60</td>\n      <td>Andorra</td>\n      <td>77265</td>\n      <td>470.0</td>\n      <td>164</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>358bd9e861</td>\n      <td>Sons of ****, why couldn`t they put them on t...</td>\n      <td>Sons of ****,</td>\n      <td>negative</td>\n      <td>noon</td>\n      <td>60-70</td>\n      <td>Angola</td>\n      <td>32866272</td>\n      <td>1246700.0</td>\n      <td>26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":106},{"cell_type":"code","source":"dataset.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:07.716206Z","iopub.execute_input":"2026-01-17T10:06:07.716902Z","iopub.status.idle":"2026-01-17T10:06:07.732701Z","shell.execute_reply.started":"2026-01-17T10:06:07.716873Z","shell.execute_reply":"2026-01-17T10:06:07.732222Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"dataset.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:09.376342Z","iopub.execute_input":"2026-01-17T10:06:09.377043Z","iopub.status.idle":"2026-01-17T10:06:09.392482Z","shell.execute_reply.started":"2026-01-17T10:06:09.377014Z","shell.execute_reply":"2026-01-17T10:06:09.391806Z"}},"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"textID              0\ntext                0\nselected_text       0\nsentiment           0\nTime of Tweet       0\nAge of User         0\nCountry             0\nPopulation -2020    0\nLand Area (Km²)     0\nDensity (P/Km²)     0\ndtype: int64"},"metadata":{}}],"execution_count":108},{"cell_type":"code","source":"dataset[\"text\"] = dataset[\"text\"].astype(str)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:12.156836Z","iopub.execute_input":"2026-01-17T10:06:12.157153Z","iopub.status.idle":"2026-01-17T10:06:12.162340Z","shell.execute_reply.started":"2026-01-17T10:06:12.157126Z","shell.execute_reply":"2026-01-17T10:06:12.161718Z"}},"outputs":[],"execution_count":109},{"cell_type":"code","source":"dataset[\"text\"] = dataset[\"text\"].str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:13.981446Z","iopub.execute_input":"2026-01-17T10:06:13.982223Z","iopub.status.idle":"2026-01-17T10:06:14.117986Z","shell.execute_reply.started":"2026-01-17T10:06:13.982186Z","shell.execute_reply":"2026-01-17T10:06:14.117441Z"}},"outputs":[],"execution_count":110},{"cell_type":"code","source":"LABEL_MAP = {\n    \"negative\": 0,\n    \"neutral\": 1,\n    \"positive\": 2\n}\n\ndataset[\"label\"] = dataset[\"sentiment\"].map(LABEL_MAP)\ndataset = dataset.dropna(subset=[\"label\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:15.361423Z","iopub.execute_input":"2026-01-17T10:06:15.362045Z","iopub.status.idle":"2026-01-17T10:06:15.377090Z","shell.execute_reply.started":"2026-01-17T10:06:15.362017Z","shell.execute_reply":"2026-01-17T10:06:15.376479Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"dataset=dataset[[\"text\",\"label\"]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:17.036466Z","iopub.execute_input":"2026-01-17T10:06:17.037182Z","iopub.status.idle":"2026-01-17T10:06:17.042880Z","shell.execute_reply.started":"2026-01-17T10:06:17.037153Z","shell.execute_reply":"2026-01-17T10:06:17.042155Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"import tiktoken\ntokenizer = tiktoken.get_encoding(\"gpt2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:17.956278Z","iopub.execute_input":"2026-01-17T10:06:17.956883Z","iopub.status.idle":"2026-01-17T10:06:17.960246Z","shell.execute_reply.started":"2026-01-17T10:06:17.956855Z","shell.execute_reply":"2026-01-17T10:06:17.959631Z"}},"outputs":[],"execution_count":113},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T09:22:40.176316Z","iopub.execute_input":"2026-01-17T09:22:40.176851Z","iopub.status.idle":"2026-01-17T09:22:40.180351Z","shell.execute_reply.started":"2026-01-17T09:22:40.176824Z","shell.execute_reply":"2026-01-17T09:22:40.179796Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"sentiment_counts = dataset[\"label\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:19.736688Z","iopub.execute_input":"2026-01-17T10:06:19.737000Z","iopub.status.idle":"2026-01-17T10:06:19.741412Z","shell.execute_reply.started":"2026-01-17T10:06:19.736974Z","shell.execute_reply":"2026-01-17T10:06:19.740669Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"plt.figure()\nplt.bar(sentiment_counts.index, sentiment_counts.values)\nplt.xlabel(\"Sentiment\")\nplt.ylabel(\"Count\")\nplt.title(\"Sentiment Distribution\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:21.346376Z","iopub.execute_input":"2026-01-17T10:06:21.346902Z","iopub.status.idle":"2026-01-17T10:06:21.454238Z","shell.execute_reply.started":"2026-01-17T10:06:21.346874Z","shell.execute_reply":"2026-01-17T10:06:21.453655Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":115},{"cell_type":"code","source":"dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:23.206500Z","iopub.execute_input":"2026-01-17T10:06:23.207160Z","iopub.status.idle":"2026-01-17T10:06:23.214870Z","shell.execute_reply.started":"2026-01-17T10:06:23.207128Z","shell.execute_reply":"2026-01-17T10:06:23.214253Z"}},"outputs":[],"execution_count":116},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:24.496727Z","iopub.execute_input":"2026-01-17T10:06:24.497074Z","iopub.status.idle":"2026-01-17T10:06:24.503197Z","shell.execute_reply.started":"2026-01-17T10:06:24.497048Z","shell.execute_reply":"2026-01-17T10:06:24.502316Z"}},"outputs":[],"execution_count":117},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:05:00.636158Z","iopub.execute_input":"2026-01-17T10:05:00.636414Z","iopub.status.idle":"2026-01-17T10:05:00.639934Z","shell.execute_reply.started":"2026-01-17T10:05:00.636392Z","shell.execute_reply":"2026-01-17T10:05:00.639293Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"df_train,df_test=train_test_split(dataset,test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:35:02.778526Z","iopub.execute_input":"2026-01-17T10:35:02.779097Z","iopub.status.idle":"2026-01-17T10:35:02.787369Z","shell.execute_reply.started":"2026-01-17T10:35:02.779065Z","shell.execute_reply":"2026-01-17T10:35:02.786535Z"}},"outputs":[],"execution_count":129},{"cell_type":"code","source":"df_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:35:09.648542Z","iopub.execute_input":"2026-01-17T10:35:09.649012Z","iopub.status.idle":"2026-01-17T10:35:09.657867Z","shell.execute_reply.started":"2026-01-17T10:35:09.648980Z","shell.execute_reply":"2026-01-17T10:35:09.657065Z"}},"outputs":[{"execution_count":130,"output_type":"execute_result","data":{"text/plain":"                                                    text  label\n22903                                  has a tummy ache.      0\n14565                          _M Thanks for remembering      2\n12541  Happy Star Wars Day! .... May the 4th Be with ...      2\n16647  #liesboystell Your the only one, I love (they ...      0\n2020   aww sorry to hear you are having a bad time. R...      0\n...                                                  ...    ...\n8221               People are just pisssing me offf. Ugh      0\n24564      oops. Cy`s place is too near. Trouble for me.      0\n23790        In rural #thailand, 2630 is considered posh      1\n293    Har Har, #swineflu is everywhere: http://twitp...      1\n24359  My trip to Igbaras will be postponed to next week      1\n\n[21984 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22903</th>\n      <td>has a tummy ache.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14565</th>\n      <td>_M Thanks for remembering</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12541</th>\n      <td>Happy Star Wars Day! .... May the 4th Be with ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>16647</th>\n      <td>#liesboystell Your the only one, I love (they ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2020</th>\n      <td>aww sorry to hear you are having a bad time. R...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8221</th>\n      <td>People are just pisssing me offf. Ugh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>24564</th>\n      <td>oops. Cy`s place is too near. Trouble for me.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23790</th>\n      <td>In rural #thailand, 2630 is considered posh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>293</th>\n      <td>Har Har, #swineflu is everywhere: http://twitp...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24359</th>\n      <td>My trip to Igbaras will be postponed to next week</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>21984 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":130},{"cell_type":"code","source":"leno= dataset[\"text\"].apply(\n    lambda x: len(tokenizer.encode(x))\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:28.036427Z","iopub.execute_input":"2026-01-17T10:06:28.037217Z","iopub.status.idle":"2026-01-17T10:06:28.317041Z","shell.execute_reply.started":"2026-01-17T10:06:28.037178Z","shell.execute_reply":"2026-01-17T10:06:28.316266Z"}},"outputs":[],"execution_count":119},{"cell_type":"code","source":"leno.plot(kind=\"hist\",bins=30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:29.506651Z","iopub.execute_input":"2026-01-17T10:06:29.507275Z","iopub.status.idle":"2026-01-17T10:06:29.650397Z","shell.execute_reply.started":"2026-01-17T10:06:29.507245Z","shell.execute_reply":"2026-01-17T10:06:29.649830Z"}},"outputs":[{"execution_count":120,"output_type":"execute_result","data":{"text/plain":"<Axes: ylabel='Frequency'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":120},{"cell_type":"code","source":"leno.describe(percentiles=[0.9, 0.95, 0.99])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:06:31.556595Z","iopub.execute_input":"2026-01-17T10:06:31.557293Z","iopub.status.idle":"2026-01-17T10:06:31.565379Z","shell.execute_reply.started":"2026-01-17T10:06:31.557264Z","shell.execute_reply":"2026-01-17T10:06:31.564742Z"}},"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"count    27480.000000\nmean        18.007387\nstd          9.566531\nmin          1.000000\n50%         17.000000\n90%         31.000000\n95%         35.000000\n99%         40.000000\nmax        110.000000\nName: text, dtype: float64"},"metadata":{}}],"execution_count":121},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\n\nclass SentimentDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.texts = dataframe[\"text\"].fillna(\"\").astype(str).tolist()\n        self.labels = dataframe[\"label\"].tolist()\n        self.tokenizer = tokenizer\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]  # ✅ use iloc, not loc or df[idx]\n        text = str(row[\"text\"])\n        tokens=self.tokenizer.encode(text)\n        labels = int(row[\"sentiment\"])\n\n        return {\n            \"input_ids\": torch.tensor(tokens, dtype=torch.long),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:12:05.079331Z","iopub.execute_input":"2026-01-17T11:12:05.079633Z","iopub.status.idle":"2026-01-17T11:12:05.085598Z","shell.execute_reply.started":"2026-01-17T11:12:05.079607Z","shell.execute_reply":"2026-01-17T11:12:05.085031Z"}},"outputs":[],"execution_count":163},{"cell_type":"code","source":"MAX_LEN = CONFIG[\"context_length\"]\n\ndef collate_fn(batch):\n    input_ids = [item[\"input_ids\"][:MAX_LEN] for item in batch]\n    labels = torch.stack([item[\"labels\"] for item in batch])\n\n    input_ids = pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.eot_token\n    )\n\n    attention_mask = (input_ids != tokenizer.eot_token).long()\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:12:10.853635Z","iopub.execute_input":"2026-01-17T11:12:10.854242Z","iopub.status.idle":"2026-01-17T11:12:10.858899Z","shell.execute_reply.started":"2026-01-17T11:12:10.854211Z","shell.execute_reply":"2026-01-17T11:12:10.858231Z"}},"outputs":[],"execution_count":164},{"cell_type":"code","source":"\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.nn.utils.rnn import pad_sequence\n\nclass SentimentDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.texts = dataframe[\"text\"].fillna(\"\").astype(str).tolist()\n        self.labels = dataframe[\"label\"].tolist()\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        # Use the pre-processed lists instead of accessing dataframe\n        text = self.texts[idx]\n        label = self.labels[idx]\n        \n        # Tokenize the text\n        tokens = self.tokenizer.encode(text)\n        \n        return {\n            \"input_ids\": torch.tensor(tokens, dtype=torch.long),\n            \"labels\": torch.tensor(label, dtype=torch.long),\n        }\n\n# Collate function\ndef collate_fn(batch, tokenizer, max_len):\n    input_ids = [item[\"input_ids\"][:max_len] for item in batch]\n    labels = torch.stack([item[\"labels\"] for item in batch])\n    \n    input_ids = pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.eot_token\n    )\n    \n    attention_mask = (input_ids != tokenizer.eot_token).long()\n    \n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:15:05.694717Z","iopub.execute_input":"2026-01-17T11:15:05.695128Z","iopub.status.idle":"2026-01-17T11:15:05.706938Z","shell.execute_reply.started":"2026-01-17T11:15:05.695060Z","shell.execute_reply":"2026-01-17T11:15:05.705478Z"}},"outputs":[],"execution_count":173},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataset = SentimentDataset(df_train, tokenizer)\nval_dataset   = SentimentDataset(df_test, tokenizer)\n\ntrain_loader = DataLoader(\n    df_train,\n    batch_size=32,\n    shuffle=True,\n    collate_fn=collate_fn,\n    num_workers=0,\n    pin_memory=True\n)\n\nval_loader = DataLoader(\n    df_test,\n    batch_size=32,\n    shuffle=False,\n    collate_fn=collate_fn,\n    num_workers=0,\n    pin_memory=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:15:35.859610Z","iopub.execute_input":"2026-01-17T11:15:35.859971Z","iopub.status.idle":"2026-01-17T11:15:35.877318Z","shell.execute_reply.started":"2026-01-17T11:15:35.859917Z","shell.execute_reply":"2026-01-17T11:15:35.876626Z"}},"outputs":[],"execution_count":176},{"cell_type":"code","source":"def train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(dataloader, desc=\"Training\")\n    for batch in pbar:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        optimizer.zero_grad()\n        \n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        _, predicted = torch.max(logits, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n        \n        pbar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'acc': f'{100 * correct / total:.2f}%'\n        })\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100 * correct / total\n    \n    return avg_loss, accuracy\n\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc=\"Validation\")\n        for batch in pbar:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            \n            total_loss += loss.item()\n            \n            _, predicted = torch.max(logits, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n            pbar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'acc': f'{100 * correct / total:.2f}%'\n            })\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100 * correct / total\n    \n    return avg_loss, accuracy\n\n\n# ==================== PREDICTION ====================\n\ndef predict(model, text, tokenizer, device, max_len=80):\n    \"\"\"Predict sentiment for a single text\"\"\"\n    model.eval()\n    \n    # Tokenize\n    tokens = tokenizer.encode(text)[:max_len]\n    input_ids = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n    attention_mask = torch.ones_like(input_ids).to(device)\n    \n    with torch.no_grad():\n        logits = model(input_ids, attention_mask)\n        probabilities = torch.softmax(logits, dim=1)\n        predicted_class = torch.argmax(logits, dim=1).item()\n    \n    label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n    \n    return {\n        \"predicted_class\": predicted_class,\n        \"predicted_label\": label_map[predicted_class],\n        \"probabilities\": {\n            \"negative\": probabilities[0][0].item(),\n            \"neutral\": probabilities[0][1].item(),\n            \"positive\": probabilities[0][2].item()\n        }\n    }\n\n\ndef predict_batch(model, dataloader, device):\n    \"\"\"Predict sentiment for a batch of texts\"\"\"\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Predicting\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            _, predicted = torch.max(logits, 1)\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    return np.array(all_predictions), np.array(all_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T10:58:55.878446Z","iopub.execute_input":"2026-01-17T10:58:55.879172Z","iopub.status.idle":"2026-01-17T10:58:55.894090Z","shell.execute_reply.started":"2026-01-17T10:58:55.879142Z","shell.execute_reply":"2026-01-17T10:58:55.893248Z"}},"outputs":[],"execution_count":139},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\ntokenizer = tiktoken.get_encoding(\"gpt2\")\nmodel = GPTModel( CONFIG).to(device)\n    \n    # Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n    \n    # Training loop\nnum_epochs = 3\nbest_val_acc = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:06:43.418611Z","iopub.execute_input":"2026-01-17T11:06:43.419249Z","iopub.status.idle":"2026-01-17T11:06:49.301716Z","shell.execute_reply.started":"2026-01-17T11:06:43.419219Z","shell.execute_reply":"2026-01-17T11:06:49.301171Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":155},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n    print(\"-\" * 50)\n    \n    # Train\n    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n    \n    # Validate\n    val_loss, val_acc = validate(model, val_loader, criterion, device)\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n    \n    # Save best model\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), 'best_model.pth')\n        print(f\"Saved best model with accuracy: {best_val_acc:.2f}%\")\n\n# Example prediction\nsample_text = \"I love this product! It's amazing!\"\nresult = predict(model, sample_text, tokenizer, device)\nprint(f\"\\nSample prediction: {result}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:15:40.668662Z","iopub.execute_input":"2026-01-17T11:15:40.668984Z","iopub.status.idle":"2026-01-17T11:15:40.695208Z","shell.execute_reply.started":"2026-01-17T11:15:40.668950Z","shell.execute_reply":"2026-01-17T11:15:40.694204Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1/3\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/687 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 12424","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/702703724.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/308480670.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 12424"],"ename":"KeyError","evalue":"12424","output_type":"error"}],"execution_count":177},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset, DataLoader\nimport tiktoken\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# ==================== Configuration ====================\nCONFIG = {\n    \"vocab_size\": 50257,\n    \"context_length\": 80,\n    \"emb_dim\": 768,\n    \"n_heads\": 6,\n    \"n_layers\": 6,\n    \"drop_rate\": 0.1,\n    \"qkv_bias\": False\n}\n\nEOT_TOKEN_ID = 50256\n\n# ==================== Model Components ====================\nclass GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n            (x + 0.044715 * torch.pow(x, 3))\n        ))\n\n\nclass SelfAttention(nn.Module):\n    def __init__(self, d_in, d_out, context_length, qkv_bias=False):\n        super().__init__()\n        self.d_out = d_out\n        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n        self.dropout = nn.Dropout(0.01)\n\n    def forward(self, x, attention_mask=None):\n        keys = self.W_key(x)\n        queries = self.W_query(x)\n        values = self.W_value(x)\n        \n        attn_scores = queries @ keys.transpose(1, 2)\n        \n        if attention_mask is not None:\n            mask = attention_mask[:, None, :]\n            attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n        \n        attn_weights = torch.softmax(attn_scores / (keys.shape[-1] ** 0.5), dim=-1)\n        attn_weights = self.dropout(attn_weights)\n        \n        context_vec = attn_weights @ values\n        return context_vec\n\n\nclass MultiHeadAttentionWrapper(nn.Module):\n    def __init__(self, d_in, d_out, context_length, num_heads, qkv_bias=False):\n        super().__init__()\n        self.heads = nn.ModuleList([\n            SelfAttention(d_in, d_out, context_length, qkv_bias) \n            for _ in range(num_heads)\n        ])\n\n    def forward(self, x, mask):\n        return torch.cat([head(x, mask) for head in self.heads], dim=-1)\n\n\nclass FeedForward(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n            GELU(),\n            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n\nclass TransformerBlock(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.att = MultiHeadAttentionWrapper(\n            d_in=cfg[\"emb_dim\"],\n            d_out=cfg[\"emb_dim\"] // cfg[\"n_heads\"],\n            context_length=cfg[\"context_length\"],\n            num_heads=cfg[\"n_heads\"], \n            qkv_bias=cfg[\"qkv_bias\"]\n        )\n        self.ff = FeedForward(cfg)\n        self.norm1 = nn.LayerNorm(cfg[\"emb_dim\"])\n        self.norm2 = nn.LayerNorm(cfg[\"emb_dim\"])\n        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n\n    def forward(self, x, mask):\n        shortcut = x\n        x = self.norm1(x)\n        x = self.att(x, mask)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        shortcut = x\n        x = self.norm2(x)\n        x = self.ff(x)\n        x = self.drop_shortcut(x)\n        x = x + shortcut\n\n        return x\n\n\nclass GPTModel(nn.Module):\n    def __init__(self, cfg):\n        super().__init__()\n        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n        \n        self.trf_blocks = nn.ModuleList([\n            TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])\n        ])\n        \n        self.final_norm = nn.LayerNorm(cfg[\"emb_dim\"])\n        self.out_head = nn.Linear(cfg[\"emb_dim\"], 3, bias=True)  # 3 classes\n\n    def forward(self, in_idx, mask):\n        batch_size, seq_len = in_idx.shape\n        tok_embeds = self.tok_emb(in_idx)\n        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n        x = tok_embeds + pos_embeds\n        x = self.drop_emb(x)\n        \n        for block in self.trf_blocks:\n            x = block(x, mask)\n        \n        x = self.final_norm(x)\n        # Pool: take mean of all tokens (excluding padding)\n        mask_expanded = mask.unsqueeze(-1).float()\n        x = (x * mask_expanded).sum(dim=1) / mask_expanded.sum(dim=1)\n        logits = self.out_head(x)\n        return logits\n\n\n# ==================== Dataset ====================\nclass SentimentDataset(Dataset):\n    def __init__(self, dataframe, tokenizer):\n        self.texts = dataframe[\"text\"].fillna(\"\").astype(str).tolist()\n        self.labels = dataframe[\"label\"].tolist()\n        self.tokenizer = tokenizer\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        tokens = self.tokenizer.encode(text)\n        \n        return {\n            \"input_ids\": torch.tensor(tokens, dtype=torch.long),\n            \"labels\": torch.tensor(label, dtype=torch.long),\n        }\n\n\ndef collate_fn(batch, max_len=80):\n    input_ids = [item[\"input_ids\"][:max_len] for item in batch]\n    labels = torch.stack([item[\"labels\"] for item in batch])\n    \n    input_ids = pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=EOT_TOKEN_ID\n    )\n    \n    attention_mask = (input_ids != EOT_TOKEN_ID).long()\n    \n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"labels\": labels\n    }\n\n\n# ==================== Training Functions ====================\ndef train_epoch(model, dataloader, optimizer, criterion, device):\n    model.train()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(dataloader, desc=\"Training\")\n    for batch in pbar:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        \n        optimizer.zero_grad()\n        \n        logits = model(input_ids, attention_mask)\n        loss = criterion(logits, labels)\n        \n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        _, predicted = torch.max(logits, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n        \n        pbar.set_postfix({\n            'loss': f'{loss.item():.4f}',\n            'acc': f'{100 * correct / total:.2f}%'\n        })\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100 * correct / total\n    \n    return avg_loss, accuracy\n\n\ndef validate(model, dataloader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc=\"Validation\")\n        for batch in pbar:\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            loss = criterion(logits, labels)\n            \n            total_loss += loss.item()\n            \n            _, predicted = torch.max(logits, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n            \n            pbar.set_postfix({\n                'loss': f'{loss.item():.4f}',\n                'acc': f'{100 * correct / total:.2f}%'\n            })\n    \n    avg_loss = total_loss / len(dataloader)\n    accuracy = 100 * correct / total\n    \n    return avg_loss, accuracy\n\n\n# ==================== Main Training Script ====================\nif __name__ == \"__main__\":\n    # Load dataset\n    dataset = pd.read_csv(\"/kaggle/input/sentiment-analysis-dataset/train.csv\", encoding=\"latin1\")\n    \n    # Preprocessing\n    dataset.dropna(inplace=True)\n    dataset[\"text\"] = dataset[\"text\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n    \n    LABEL_MAP = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n    dataset[\"label\"] = dataset[\"sentiment\"].map(LABEL_MAP)\n    dataset = dataset.dropna(subset=[\"label\"])\n    dataset = dataset[[\"text\", \"label\"]]\n    \n    # Shuffle\n    dataset = dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    # Split\n    df_train, df_test = train_test_split(dataset, test_size=0.2, random_state=42)\n    \n    # Tokenizer\n    tokenizer = tiktoken.get_encoding(\"gpt2\")\n    \n    # Create datasets\n    train_dataset = SentimentDataset(df_train, tokenizer)\n    val_dataset = SentimentDataset(df_test, tokenizer)\n    \n    # Create dataloaders with lambda to pass max_len\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=32,\n        shuffle=True,\n        collate_fn=lambda batch: collate_fn(batch, max_len=CONFIG[\"context_length\"]),\n        num_workers=0,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=32,\n        shuffle=False,\n        collate_fn=lambda batch: collate_fn(batch, max_len=CONFIG[\"context_length\"]),\n        num_workers=0,\n        pin_memory=True\n    )\n    \n    # Setup\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    \n    model = GPTModel(CONFIG).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n    \n    # Training loop\n    num_epochs = 3\n    best_val_acc = 0\n    \n    for epoch in range(num_epochs):\n        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n        print(\"-\" * 50)\n        \n        train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, device)\n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n        \n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')\n            print(f\"Saved best model with accuracy: {best_val_acc:.2f}%\")\n    \n    print(f\"\\nTraining completed! Best validation accuracy: {best_val_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:18:13.509860Z","iopub.execute_input":"2026-01-17T11:18:13.510734Z","iopub.status.idle":"2026-01-17T11:21:17.951150Z","shell.execute_reply.started":"2026-01-17T11:18:13.510702Z","shell.execute_reply":"2026-01-17T11:21:17.950275Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n\nEpoch 1/3\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 687/687 [00:56<00:00, 12.17it/s, loss=0.9067, acc=50.43%]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9852, Train Acc: 50.43%\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 172/172 [00:04<00:00, 41.49it/s, loss=0.8967, acc=56.39%]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.9020, Val Acc: 56.39%\nSaved best model with accuracy: 56.39%\n\nEpoch 2/3\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 687/687 [00:56<00:00, 12.20it/s, loss=0.8816, acc=59.56%]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.8528, Train Acc: 59.56%\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 172/172 [00:04<00:00, 41.26it/s, loss=0.8255, acc=60.77%]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8420, Val Acc: 60.77%\nSaved best model with accuracy: 60.77%\n\nEpoch 3/3\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 687/687 [00:56<00:00, 12.17it/s, loss=0.8404, acc=65.93%]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.7577, Train Acc: 65.93%\n","output_type":"stream"},{"name":"stderr","text":"Validation: 100%|██████████| 172/172 [00:04<00:00, 41.30it/s, loss=0.7958, acc=62.79%]\n","output_type":"stream"},{"name":"stdout","text":"Val Loss: 0.8224, Val Acc: 62.79%\nSaved best model with accuracy: 62.79%\n\nTraining completed! Best validation accuracy: 62.79%\n","output_type":"stream"}],"execution_count":179},{"cell_type":"code","source":"def predict(model, text, tokenizer, device, max_len=80):\n    \"\"\"\n    Predict sentiment for a single text string.\n    \n    Args:\n        model: Trained GPTModel\n        text: Input text string\n        tokenizer: Tiktoken tokenizer\n        device: torch device\n        max_len: Maximum sequence length\n    \n    Returns:\n        Dictionary with predicted class, label, and probabilities\n    \"\"\"\n    model.eval()\n    \n    # Tokenize\n    tokens = tokenizer.encode(text)[:max_len]\n    input_ids = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n    attention_mask = torch.ones_like(input_ids).to(device)\n    \n    with torch.no_grad():\n        logits = model(input_ids, attention_mask)\n        probabilities = torch.softmax(logits, dim=1)\n        predicted_class = torch.argmax(logits, dim=1).item()\n    \n    label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n    \n    return {\n        \"text\": text,\n        \"predicted_class\": predicted_class,\n        \"predicted_label\": label_map[predicted_class],\n        \"probabilities\": {\n            \"negative\": f\"{probabilities[0][0].item():.4f}\",\n            \"neutral\": f\"{probabilities[0][1].item():.4f}\",\n            \"positive\": f\"{probabilities[0][2].item():.4f}\"\n        }\n    }\n\n\ndef predict_batch(model, texts, tokenizer, device, max_len=80, batch_size=32):\n    \"\"\"\n    Predict sentiment for multiple texts efficiently.\n    \n    Args:\n        model: Trained GPTModel\n        texts: List of text strings\n        tokenizer: Tiktoken tokenizer\n        device: torch device\n        max_len: Maximum sequence length\n        batch_size: Batch size for prediction\n    \n    Returns:\n        List of prediction dictionaries\n    \"\"\"\n    model.eval()\n    all_predictions = []\n    label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n    \n    # Process in batches\n    for i in range(0, len(texts), batch_size):\n        batch_texts = texts[i:i + batch_size]\n        \n        # Tokenize batch\n        batch_tokens = [tokenizer.encode(text)[:max_len] for text in batch_texts]\n        batch_ids = [torch.tensor(tokens, dtype=torch.long) for tokens in batch_tokens]\n        \n        # Pad sequences\n        input_ids = pad_sequence(batch_ids, batch_first=True, padding_value=EOT_TOKEN_ID).to(device)\n        attention_mask = (input_ids != EOT_TOKEN_ID).long().to(device)\n        \n        with torch.no_grad():\n            logits = model(input_ids, attention_mask)\n            probabilities = torch.softmax(logits, dim=1)\n            predicted_classes = torch.argmax(logits, dim=1)\n        \n        # Format results\n        for j, text in enumerate(batch_texts):\n            all_predictions.append({\n                \"text\": text,\n                \"predicted_class\": predicted_classes[j].item(),\n                \"predicted_label\": label_map[predicted_classes[j].item()],\n                \"probabilities\": {\n                    \"negative\": f\"{probabilities[j][0].item():.4f}\",\n                    \"neutral\": f\"{probabilities[j][1].item():.4f}\",\n                    \"positive\": f\"{probabilities[j][2].item():.4f}\"\n                }\n            })\n    \n    return all_predictions\n\n\ndef evaluate_with_metrics(model, dataloader, device):\n    \"\"\"\n    Evaluate model and return detailed metrics including confusion matrix.\n    \n    Args:\n        model: Trained GPTModel\n        dataloader: DataLoader with test data\n        device: torch device\n    \n    Returns:\n        Dictionary with accuracy, predictions, and true labels\n    \"\"\"\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].to(device)\n            \n            logits = model(input_ids, attention_mask)\n            _, predicted = torch.max(logits, 1)\n            \n            all_predictions.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    \n    all_predictions = np.array(all_predictions)\n    all_labels = np.array(all_labels)\n    \n    accuracy = (all_predictions == all_labels).sum() / len(all_labels)\n    \n    return {\n        \"accuracy\": accuracy,\n        \"predictions\": all_predictions,\n        \"true_labels\": all_labels,\n        \"num_samples\": len(all_labels)\n    }\n\n\n# ==================== Example Usage ====================\n\n# After training, load the best model:\nmodel.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n\n# Single prediction\nresult = predict(model, \"I love this product! It's amazing!\", tokenizer, device)\nprint(result)\n\n# Batch prediction\ntexts = [\n    \"This is terrible, I hate it!\",\n    \"It's okay, nothing special.\",\n    \"Absolutely fantastic! Best purchase ever!\"\n]\nresults = predict_batch(model, texts, tokenizer, device)\nfor r in results:\n    print(f\"{r['text'][:50]}... -> {r['predicted_label']} ({r['probabilities']})\")\n\n# Full evaluation\nmetrics = evaluate_with_metrics(model, val_loader, device)\nprint(f\"Test Accuracy: {metrics['accuracy']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T11:22:54.299884Z","iopub.execute_input":"2026-01-17T11:22:54.300231Z","iopub.status.idle":"2026-01-17T11:22:58.651253Z","shell.execute_reply.started":"2026-01-17T11:22:54.300203Z","shell.execute_reply":"2026-01-17T11:22:58.650585Z"}},"outputs":[{"name":"stdout","text":"{'text': \"I love this product! It's amazing!\", 'predicted_class': 2, 'predicted_label': 'positive', 'probabilities': {'negative': '0.0005', 'neutral': '0.0034', 'positive': '0.9961'}}\nThis is terrible, I hate it!... -> negative ({'negative': '0.9559', 'neutral': '0.0321', 'positive': '0.0120'})\nIt's okay, nothing special.... -> neutral ({'negative': '0.1398', 'neutral': '0.7618', 'positive': '0.0984'})\nAbsolutely fantastic! Best purchase ever!... -> positive ({'negative': '0.0127', 'neutral': '0.0359', 'positive': '0.9514'})\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 172/172 [00:03<00:00, 43.09it/s]","output_type":"stream"},{"name":"stdout","text":"Test Accuracy: 0.6279\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":180},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}